{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import polars as pl\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "ROOT_DIR = Path(os.environ[\"OOCHA_DIR\"])\n",
    "RESULTS_DIR = Path(\"results\")\n",
    "STUDY_NAME = \"MLP\"\n",
    "SAMPLE_LENGTH = 1500\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(f\"Running with device: {torch.cuda.get_device_name(DEVICE)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from torch import nn\n",
    "\n",
    "from src.cci.models import LambdaLayer\n",
    "\n",
    "\n",
    "def suggest_mlp(trial: optuna.Trial) -> list[nn.Module]:\n",
    "    n_hidden_layers = trial.suggest_int(\"n_hidden_layers\", 1, 3)\n",
    "    i = 1\n",
    "    layers: list[nn.Module] = [\n",
    "        nn.Flatten(),\n",
    "        nn.Dropout(trial.suggest_float(f\"dropout_{i}\", 0.1, 0.5)),\n",
    "    ]\n",
    "    features = trial.suggest_int(f\"linear_{i}\", 1, 1000)\n",
    "    prev_features = features\n",
    "    layers.append(nn.LazyLinear(features))\n",
    "    layers.append(nn.ReLU())\n",
    "    for _ in range(n_hidden_layers - 1):\n",
    "        i += 1\n",
    "        features = trial.suggest_int(f\"linear_{i}\", 1, 1000)\n",
    "\n",
    "        layers.append(nn.Dropout(trial.suggest_float(f\"dropout_{i}\", 0.1, 0.5)))\n",
    "        layers.append(nn.Linear(prev_features, features))\n",
    "        layers.append(nn.ReLU())\n",
    "        prev_features = features\n",
    "    i += 1\n",
    "    layers.append(nn.Dropout(trial.suggest_float(f\"dropout_{i}\", 0.1, 0.5)))\n",
    "    layers.append(nn.Linear(prev_features, 1))\n",
    "    layers.append(LambdaLayer(lambda x: x.view(-1)))\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict\n",
    "import numpy as np\n",
    "from rich.live import Live\n",
    "from rich.progress import (\n",
    "    Progress,\n",
    "    TextColumn,\n",
    "    TimeElapsedColumn,\n",
    ")\n",
    "from rich.table import Table\n",
    "from torch.nn import functional as F\n",
    "from src.cci.metrics import Metrics\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def fit(\n",
    "    model: nn.Module,\n",
    "    opt: torch.optim.Optimizer,\n",
    "    loss_fn: nn.BCEWithLogitsLoss,\n",
    "    val_loss_fn: nn.BCEWithLogitsLoss,\n",
    "    train_metrics: Metrics,\n",
    "    val_metrics: Metrics,\n",
    "    train_loader: DataLoader,\n",
    "    val_loader: DataLoader,\n",
    "    epochs: int,\n",
    ") -> tuple[Metrics, Metrics, Dict[str, Any]]:\n",
    "    table = Table(\"Training model: TODO\")\n",
    "    metric_info = Progress(TextColumn(\"{task.description}\"))\n",
    "    task_metrics = metric_info.add_task(\"Metrics\")\n",
    "    progress = Progress(*Progress.get_default_columns(), TimeElapsedColumn())\n",
    "    task_epoch = progress.add_task(\"Epochs\")\n",
    "    task_train = progress.add_task(\"Train\")\n",
    "    task_validation = progress.add_task(\"Validation\")\n",
    "    table.add_row(progress)\n",
    "    table.add_row(metric_info)\n",
    "\n",
    "    best_loss = np.inf\n",
    "    best_model = model.state_dict()\n",
    "    with Live(table):\n",
    "        for epoch in progress.track(range(1, epochs + 1), description=\"Epochs\", task_id=task_epoch):\n",
    "            progress.reset(task_validation)\n",
    "            train_metrics.reset()\n",
    "            model.train()\n",
    "\n",
    "            for data in progress.track(train_loader, description=\"Training\", task_id=task_train):\n",
    "                sample, label = data[\"signal\"].to(DEVICE), data[\"label\"].to(DEVICE)\n",
    "                opt.zero_grad()\n",
    "                logits = model(sample)\n",
    "\n",
    "                loss = loss_fn(logits, label.float())\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "\n",
    "                predictions = F.sigmoid(logits)\n",
    "                train_metrics.update(predictions, label, loss)\n",
    "            train_metrics.save_metrics(epoch)\n",
    "\n",
    "            # Track weights\n",
    "            # track_params_dists(model, run)\n",
    "            # track_gradients_dists(model, run)\n",
    "\n",
    "            val_metrics.reset()\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for data in progress.track(val_loader, description=\"Validation\", task_id=task_validation):\n",
    "                    sample, label = data[\"signal\"].to(DEVICE), data[\"label\"].to(DEVICE)\n",
    "                    logits = model(sample)\n",
    "\n",
    "                    loss = val_loss_fn(logits, label.float())\n",
    "\n",
    "                    predictions = F.sigmoid(logits)\n",
    "                    val_metrics.update(predictions, label, loss)\n",
    "            val_metrics.save_metrics(epoch)\n",
    "\n",
    "            validation_values = val_metrics.compute()\n",
    "            training_values = train_metrics.compute()\n",
    "            metric_info.update(\n",
    "                task_id=task_metrics,\n",
    "                description=f\"\\nTraining\\n Acc:{training_values['acc']:.3f}\\n Loss{training_values['loss']:.3f}\\n\"\n",
    "                f\"Validation\\n Acc:{validation_values['acc']:.3f}\\n Loss:{validation_values['loss']:.3f}\\n\",\n",
    "            )\n",
    "            if validation_values[\"loss\"] < best_loss:\n",
    "                best_loss = validation_values[\"loss\"]\n",
    "                best_model = model.state_dict()\n",
    "\n",
    "    return train_metrics, val_metrics, best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from rich.progress import track\n",
    "from deepdiff import DeepHash\n",
    "from torch import tensor, optim\n",
    "\n",
    "from src.cci.dataset.dataset import skfold\n",
    "\n",
    "\n",
    "def objective(trial: optuna.Trial):\n",
    "    optimizer_name = trial.suggest_categorical(\"Optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [4, 8, 16, 32])\n",
    "    model_layers = suggest_mlp(trial)\n",
    "    trial.study\n",
    "\n",
    "    run = {\n",
    "        \"experiment\": STUDY_NAME,\n",
    "        \"dataset\": {\n",
    "            \"set\": \"data/clean_df.csv\",\n",
    "            \"samples\": 1500,\n",
    "            \"preprocessing\": {},\n",
    "            \"test_set\": {\"augmentation\": \"random_shift\"},\n",
    "        },\n",
    "    }\n",
    "    run[\"params\"] = trial.params\n",
    "    run_hash = DeepHash(run)[run]\n",
    "\n",
    "    running_bac = 0.0\n",
    "    running_loss = 0.0\n",
    "    running_f1 = 0.0\n",
    "    splits = 5\n",
    "    run_dir = RESULTS_DIR / run[\"experiment\"] / run_hash\n",
    "    for fold_idx, (train_loader, val_loader, test_loader) in enumerate(\n",
    "        skfold(\"data/clean_df.csv\", ROOT_DIR, batch_size, n_splits=splits)\n",
    "    ):\n",
    "        model = nn.Sequential(*model_layers).to(DEVICE)\n",
    "        if fold_idx == 0:\n",
    "            run[\"model_arch\"] = str(model)\n",
    "            run_dir.mkdir(parents=True, exist_ok=True)\n",
    "            trial.set_user_attr(\"run_dir\", str(run_dir))\n",
    "\n",
    "        opt = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "        loss_fn = nn.BCEWithLogitsLoss(\n",
    "            pos_weight=tensor(train_loader.dataset.get_pos_weight()),  # type: ignore\n",
    "        )\n",
    "        val_loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "        train_metrics = Metrics(\"train\", len(train_loader.dataset), DEVICE, fold_idx)  # type: ignore\n",
    "        val_metrics = Metrics(\"val\", len(val_loader.dataset), DEVICE, fold_idx)  # type: ignore\n",
    "        test_metrics = Metrics(\"test\", len(test_loader.dataset), DEVICE, fold_idx)  # type: ignore\n",
    "\n",
    "        # Train model\n",
    "        train_metrics, val_metrics, best_model = fit(\n",
    "            model,\n",
    "            opt,\n",
    "            loss_fn,\n",
    "            val_loss_fn,\n",
    "            train_metrics,\n",
    "            val_metrics,\n",
    "            train_loader,\n",
    "            val_loader,\n",
    "            epochs=100,\n",
    "        )\n",
    "\n",
    "        running_loss += min(val_metrics.saved_metrics[\"loss\"])\n",
    "        running_bac += max(val_metrics.saved_metrics[\"bac\"])\n",
    "        running_f1 += max(val_metrics.saved_metrics[\"f1\"])\n",
    "\n",
    "        model.load_state_dict(best_model)\n",
    "        # Test the best model\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for data in track(test_loader, description=\"Testing\"):\n",
    "                sample, label = data[\"signal\"].to(DEVICE), data[\"label\"].to(DEVICE)\n",
    "                logits = model(sample)\n",
    "\n",
    "                loss = val_loss_fn(logits, label.float())\n",
    "\n",
    "                predictions = F.sigmoid(logits)\n",
    "                test_metrics.update(predictions, label, loss)\n",
    "        test_metrics.save_metrics(0)\n",
    "        train_metrics.write_metrics(run_dir)\n",
    "        val_metrics.write_metrics(run_dir)\n",
    "        test_metrics.write_metrics(run_dir)\n",
    "\n",
    "        # End experiment\n",
    "        run[\"results\"] = {\n",
    "            \"best_train\": train_metrics.best_metrics(),\n",
    "            \"best_val\": val_metrics.best_metrics(),\n",
    "        }\n",
    "        with open(run_dir / f\"{fold_idx}_results.json\", \"w\") as f:\n",
    "            json.dump(run, f, skipkeys=True, indent=4)  # Skip Non-Serializable (Path)\n",
    "\n",
    "    return running_f1 / splits, running_bac / splits, running_loss / splits\n",
    "\n",
    "\n",
    "storage = optuna.storages.RDBStorage(\n",
    "    f\"sqlite:///{RESULTS_DIR}/optuna.db\",\n",
    "    heartbeat_interval=10,\n",
    "    failed_trial_callback=optuna.storages.RetryFailedTrialCallback(),\n",
    ")\n",
    "\n",
    "study = optuna.create_study(\n",
    "    storage=storage,\n",
    "    study_name=STUDY_NAME,\n",
    "    directions=[\"maximize\", \"maximize\", \"minimize\"],\n",
    "    load_if_exists=True,\n",
    ")\n",
    "study.set_metric_names([\"f1\", \"bac\", \"loss\"])\n",
    "study.optimize(\n",
    "    objective,\n",
    "    n_trials=10,\n",
    "    show_progress_bar=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
