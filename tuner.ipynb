{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Running with device: {torch.cuda.get_device_name(DEVICE)}\")\n",
    "\n",
    "\n",
    "def split_train_test(csv: str) -> tuple[pl.DataFrame, pl.DataFrame]:\n",
    "    \"\"\"Returns train_val_df and test_df. Uses a fixed seed to always get the same test set\"\"\"\n",
    "    clean_df = pl.read_csv(csv).with_row_index()\n",
    "    (labels,) = clean_df.select(\"Class Label\")\n",
    "    labels = labels.to_numpy()\n",
    "\n",
    "    train_val_idx, test_idx = train_test_split(\n",
    "        range(len(clean_df)),\n",
    "        stratify=labels,\n",
    "        test_size=0.1,\n",
    "        random_state=0,\n",
    "    )\n",
    "\n",
    "    train_val_df = clean_df.filter(pl.col(\"index\").is_in(train_val_idx))\n",
    "    test_df = clean_df.filter(pl.col(\"index\").is_in(test_idx))\n",
    "\n",
    "    # Reindex\n",
    "    train_val_df = train_val_df.drop(\"index\").with_row_index()\n",
    "    test_df = test_df.drop(\"index\").with_row_index()\n",
    "    return train_val_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from torch import nn\n",
    "\n",
    "from src.cci.models import LambdaModule\n",
    "\n",
    "\n",
    "def suggest_mlp(trial: optuna.Trial) -> list[nn.Module]:\n",
    "    n_hidden_layers = trial.suggest_int(\"n_hidden_layers\", 1, 3)\n",
    "    i = 1\n",
    "    layers: list[nn.Module] = [\n",
    "        nn.Flatten(),\n",
    "        nn.Dropout(trial.suggest_float(f\"dropout_{i}\", 0.1, 0.5)),\n",
    "    ]\n",
    "    features = trial.suggest_int(f\"linear_{i}\", 1, 1000)\n",
    "    prev_features = features\n",
    "    layers.append(nn.LazyLinear(features))\n",
    "    layers.append(nn.ReLU())\n",
    "    for _ in range(n_hidden_layers):\n",
    "        i += 1\n",
    "        features = trial.suggest_int(f\"linear_{i}\", 1, 1000)\n",
    "\n",
    "        layers.append(nn.Dropout(trial.suggest_float(f\"dropout_{i}\", 0.1, 0.5)))\n",
    "        layers.append(nn.Linear(prev_features, features))\n",
    "        layers.append(nn.ReLU())\n",
    "        prev_features = features\n",
    "    i += 1\n",
    "    layers.append(nn.Dropout(trial.suggest_float(f\"dropout_{i}\", 0.1, 0.5)))\n",
    "    layers.append(nn.Linear(prev_features, 1))\n",
    "\n",
    "    # Convert to list\n",
    "    layers.append(LambdaModule(lambda x: x.view(-1)))\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import aim\n",
    "import numpy as np\n",
    "import optuna\n",
    "import polars as pl\n",
    "import torch\n",
    "from aim import Text\n",
    "from aim.optuna import AimCallback\n",
    "from aim.pytorch import track_gradients_dists, track_params_dists\n",
    "from rich.live import Live\n",
    "from rich.progress import (\n",
    "    Progress,\n",
    "    TextColumn,\n",
    "    TimeElapsedColumn,\n",
    ")\n",
    "from rich.table import Table\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch import nn, optim, tensor\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from src.cci.dataset.dataset import TransitionDataset\n",
    "from src.cci.dataset.transforms import CropSample, RandomSample, ToTensor\n",
    "from src.cci.metrics import Metrics\n",
    "from torch.utils import bottleneck\n",
    "\n",
    "sample_length = 1500\n",
    "EXPERIMENT_NAME = \"MLP_parameter_search\"\n",
    "\n",
    "\n",
    "def fit_model(\n",
    "    model: nn.Module,\n",
    "    opt: optim.Optimizer,\n",
    "    loss_fn: nn.BCEWithLogitsLoss,\n",
    "    val_loss_fn: nn.BCEWithLogitsLoss,\n",
    "    dataloaders: dict[str, DataLoader],\n",
    "    metrics: dict[str, Metrics],\n",
    "    run: aim.Run,\n",
    "    epochs: int,\n",
    "):\n",
    "    \"\"\"Fits model and returns the best validation f1 and loss\n",
    "    (should this maybe be the best f1 at the best loss? or best combination of the scores? (alpha * f1 - (1-alpha) * loss))\"\"\"\n",
    "    table = Table(f\"Training model: {model.parameters()}\")\n",
    "    metric_info = Progress(TextColumn(\"{task.description}\"))\n",
    "    task_metrics = metric_info.add_task(\"Metrics\")\n",
    "    progress = Progress(*Progress.get_default_columns(), TimeElapsedColumn())\n",
    "    task_epoch = progress.add_task(\"Epochs\")\n",
    "    task_train = progress.add_task(\"Training\")\n",
    "    task_validation = progress.add_task(\"Validation\")\n",
    "    table.add_row(progress)\n",
    "    table.add_row(metric_info)\n",
    "\n",
    "    with Live(table):\n",
    "        plot_cm = True\n",
    "\n",
    "        for epoch in progress.track(range(1, epochs + 1), description=\"Epochs\", task_id=task_epoch):\n",
    "            progress.reset(task_train)\n",
    "            progress.reset(task_validation)\n",
    "\n",
    "            # Training\n",
    "            metrics[\"train\"].reset()\n",
    "            model.train()\n",
    "            for data in progress.track(dataloaders[\"train\"], description=\"Training\", task_id=task_train):\n",
    "                sample, label = data[\"signal\"].to(DEVICE), data[\"label\"].to(DEVICE)\n",
    "                opt.zero_grad()\n",
    "                logits = model(sample)\n",
    "\n",
    "                loss = loss_fn(logits, label.float())\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "\n",
    "                predictions = F.sigmoid(logits)\n",
    "                metrics[\"train\"].update(predictions, label, loss)\n",
    "            metrics[\"train\"].upload_metrics_epoch(run, epoch, plot_cm)\n",
    "\n",
    "            # Validation\n",
    "            metrics[\"val\"].reset()\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for data in progress.track(dataloaders[\"val\"], description=\"Validation\", task_id=task_validation):\n",
    "                    sample, label = data[\"signal\"].to(DEVICE), data[\"label\"].to(DEVICE)\n",
    "                    logits = model(sample)\n",
    "\n",
    "                    loss = val_loss_fn(logits, label.float())\n",
    "\n",
    "                    predictions = F.sigmoid(logits)\n",
    "                    metrics[\"val\"].update(predictions, label, loss)\n",
    "            metrics[\"val\"].upload_metrics_epoch(run, epoch, plot_cm)\n",
    "\n",
    "            validation_values = metrics[\"val\"].compute()\n",
    "            training_values = metrics[\"train\"].compute()\n",
    "            metric_info.update(\n",
    "                task_id=task_metrics,\n",
    "                description=f\"\\nTraining\\n Acc:{training_values['acc']:.3f}\\n Loss{training_values['loss']:.3f}\\n\"\n",
    "                f\"Validation\\n Acc:{validation_values['acc']:.3f}\\n Loss:{validation_values['loss']:.3f}\\n\",\n",
    "            )\n",
    "            # ------------------ TODO: ----------------------------- #\n",
    "            if validation_values[\"loss\"] == metrics[\"val\"].best_metrics[\"loss\"]:\n",
    "                best_metrics = {\"loss\": validation_values[\"loss\"], \"f1\": validation_values[\"f1\"]}\n",
    "                # SAVE BEST MODEL FOR TESTING\n",
    "            # ------------------ TODO: ----------------------------- #\n",
    "\n",
    "            # Track weights\n",
    "            track_params_dists(model, run)\n",
    "            track_gradients_dists(model, run)\n",
    "            plot_cm = True if epoch % 10 == 0 else False\n",
    "\n",
    "        # Testing\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for data in progress.track(dataloaders[\"test\"], description=\"Testing\"):\n",
    "                sample, label = data[\"signal\"].to(DEVICE), data[\"label\"].to(DEVICE)\n",
    "                logits = model(sample)\n",
    "\n",
    "                loss = val_loss_fn(logits, label.float())\n",
    "\n",
    "                predictions = F.sigmoid(logits)\n",
    "                metrics[\"test\"].update(predictions, label, loss)\n",
    "\n",
    "        metrics[\"train\"].upload_training_end(run)\n",
    "        metrics[\"val\"].upload_training_end(run)\n",
    "        metrics[\"test\"].upload_test(run)\n",
    "\n",
    "        return metrics[\"val\"].best_metrics[\"f1\"], metrics[\"val\"].best_metrics[\"loss\"]\n",
    "\n",
    "\n",
    "# Tuner\n",
    "aim_callback = AimCallback(metric_name=[\"f1\", \"loss\"], as_multirun=True, experiment_name=\"MLP_parameter_search\")\n",
    "\n",
    "\n",
    "@aim_callback.track_in_aim()\n",
    "def objective(trial: optuna.Trial):\n",
    "    aim_callback.experiment[\"dataset\"] = {\n",
    "        \"samples\": 1500,\n",
    "        \"preprocessing\": {},\n",
    "        \"set\": \"data/clean_df.csv\",\n",
    "        \"test_set\": {\"augmentation\": \"random_shift\"},\n",
    "    }\n",
    "\n",
    "    optimizer_name = trial.suggest_categorical(\"Optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [4, 8, 16, 32])\n",
    "    model_layers = suggest_mlp(trial)\n",
    "\n",
    "    fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "    train_val_df, test_df = split_train_test(\"data/clean_df.csv\")\n",
    "    (labels,) = train_val_df.select(\"Class Label\")\n",
    "    labels = labels.to_numpy()\n",
    "    f1_scores = []\n",
    "    loss_scores = []\n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(fold.split(np.zeros(len(train_val_df)), labels)):\n",
    "        # Split data\n",
    "        train_df = train_val_df.filter(pl.col(\"index\").is_in(train_idx))\n",
    "        val_df = train_val_df.filter(pl.col(\"index\").is_in(val_idx))\n",
    "        root_dir = Path(os.environ[\"OOCHA_DIR\"])\n",
    "        train_dataset = TransitionDataset(\n",
    "            train_df,\n",
    "            root_dir,\n",
    "            transforms=[\n",
    "                RandomSample(sample_length),\n",
    "                ToTensor(),\n",
    "            ],\n",
    "        )\n",
    "        val_dataset = TransitionDataset(\n",
    "            val_df,\n",
    "            root_dir,\n",
    "            transforms=[\n",
    "                CropSample(sample_length),\n",
    "                ToTensor(),\n",
    "            ],\n",
    "        )\n",
    "        test_dataset = TransitionDataset(\n",
    "            test_df,\n",
    "            root_dir,\n",
    "            transforms=[\n",
    "                CropSample(sample_length),\n",
    "                ToTensor(),\n",
    "            ],\n",
    "        )\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "        )\n",
    "        val_loader = DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=batch_size,\n",
    "        )\n",
    "        test_loader = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=batch_size,\n",
    "        )\n",
    "        dataloaders = {\"train\": train_loader, \"val\": val_loader, \"test\": test_loader}\n",
    "        metrics = {\n",
    "            \"train\": Metrics(\"train\", len(train_dataset), DEVICE, fold_idx),\n",
    "            \"val\": Metrics(\"val\", len(val_dataset), DEVICE, fold_idx),\n",
    "            \"test\": Metrics(\"test\", len(test_dataset), DEVICE, fold_idx),\n",
    "        }\n",
    "\n",
    "        model = nn.Sequential(*model_layers).to(DEVICE)\n",
    "        if fold_idx == 0:\n",
    "            aim_callback.experiment.track(Text(f\"{model}\"), \"Model Architecture\")\n",
    "        opt = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "        loss_fn = nn.BCEWithLogitsLoss(\n",
    "            pos_weight=tensor(train_dataset.get_pos_weight()),\n",
    "        )\n",
    "        val_loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "        # Train the model\n",
    "        f1, loss = fit_model(\n",
    "            model, opt, loss_fn, val_loss_fn, dataloaders, metrics, run=aim_callback.experiment, epochs=1000\n",
    "        )\n",
    "        f1_scores.append(f1)\n",
    "        loss_scores.append(loss)\n",
    "\n",
    "    avg_f1 = np.average(f1_scores)\n",
    "    avg_loss = np.average(loss_scores)\n",
    "    return float(avg_f1), float(avg_loss)\n",
    "\n",
    "\n",
    "study = optuna.create_study(directions=[\"maximize\", \"minimize\"])\n",
    "study.set_metric_names([\"f1\", \"loss\"])\n",
    "\n",
    "\n",
    "study.optimize(objective, n_trials=10, callbacks=[aim_callback])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
