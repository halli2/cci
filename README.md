# Cardiac Change Indicator

## Filestructure

- data/ - Contains info about the partitioned datasets used to load the the specific signals.
- results/ - Contains results generated by model search.
- cci/models/ - contains code to create the models and suggested hyperparameters for the models.
- cci/dataset/ - contains code used to load the dataset
- cci/tune.py - code used to run the hyperparameter search (select modeltype/return metrics to optuna)
- cci/train.py - code used for training single models, called by tune.py
- cci/__main__.py - calls the other code based on input parameters with the following functions
  run `pdm run cci --help` for options
  - A test for if pytorch finds gpu `pdm run cci check-gpu`
  - Optuna dashboard to check results of hyperparameter search `pdm run cci optuna-dashboard`
  - Hyperparametersearch `pdm run cci tune-model`
- dataset.ipynb - creates csv files in the `data` folder containing info about training/val/test sets from the labeled data
  as well as manual shifts where the labeled data doesnt fit (e.g. transition overlaps slighlty with DFB)
- inference.ipynb - contains code used to rune models over a whole episode and then display the results.
- results_viewer.ipynb - contains code used to create the training history/confusion plots.
- verify_dataset.ipynb - was used to inspect the transitions to check for mislabel/overlap in transitions.
  The result from this was manually aded to `data/override_df.csv`.


## Setup

This project uses [pdm](https://pdm-project.org/en/latest/) to manage packages.
The easiest way to install necessary packages is by using pdm, but manually using pip is also possible.
Pdm is the preferred method as it uses a lockfile to ensure that the exact version of each dependency is used.
Dependencies used can be found in the `pyproject.toml` file.

For setup with pdm the following commands can be used:
```shell
pip install pdm
pdm install -G visualize -L pdm.cuda.lock

# Or if cpu version of pytorch is wanted
pdm install -G visualzie -L pdm.cpu.lock
```

Using pip (create virtual evnironment and install dependencies from pyproject.toml):
```shell
python -m venv .venv
source .venv/bin/activate
pip install .[visualize]
pip install torch==2.2.1

# Or if cpu version of pytorch is wanted
pip install torch==2.2.1 --index-url https://download.pytorch.org/whl/cpu
```


For some extra commands used to mount files and lock packages the `justfile` can be used as a reference.

## Running on Gorina (internal servers University of Stavanger)

NOTE: If setup is needed, uncomment the noted lines containing installation commands inside the `job.sh` file,
or manually run the setup on the server with python 3.11 enabled.
On gorina11 using slurm:

```shell
./job.sh CNN_even_bigger_kernel_mlp full 5 # Run model on full dataset with 5 fold cross validation
./job.sh CNN_even_bigger_kernel_mlp pe 1 # Run model on PE dataset without cross validation
```

It will run the hyperparameter search and create a `logs` folder containing the output of stdout/stderr.

## Running locally

Running locally the available options can be found by running `pdm run cci --help`.
Running `pdm run cci tune-model --help` shows all mandatory arguments and options for running the hyperparameter search.
The study names are defined in `cci/tune.py`, and dataset names are found under `data`.
An example of running the simple CNN with 5 fold cross-validation, over 100 trials, using 1000 epochs:

```sh
pdm run cci tune-model CNN_study CNN full /path/to/oohca/ --n-splits 5 --n-trials 100 --epochs 1000
```


## Results

Results will be saved to the `results` folder with a subfolder structure of `model/trial/` and in each trial the history of results and the best model found is saved.
`results/journal.log` will contain data used by optuna which can be inspected by running `pdm run cci optuna-dashboard` and opening `127.0.0.1:8080` in a browser.
